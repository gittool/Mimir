# NornicDB ARM64 Metal
# Self-contained build with local embedding support
#
# Build:  docker build -f docker/Dockerfile.arm64-metal -t nornicdb-arm64-metal .
# With BGE model embedded:
#         docker build -f docker/Dockerfile.arm64-metal --build-arg EMBED_MODEL=true -t nornicdb-arm64-metal-bge .

# =============================================================================
# Stage 1: UI
# =============================================================================
FROM node:20-alpine AS ui
WORKDIR /ui
COPY ui/package*.json ./
RUN npm ci 2>/dev/null || npm install --legacy-peer-deps
COPY ui/ .
RUN npm run build

# =============================================================================
# Stage 2: llama.cpp static library (ARM64)
# =============================================================================
FROM debian:bookworm-slim AS llama
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential cmake git ca-certificates && rm -rf /var/lib/apt/lists/*

ARG LLAMA_VERSION=b4535
WORKDIR /llama
RUN git clone --depth 1 --branch ${LLAMA_VERSION} https://github.com/ggerganov/llama.cpp.git . && \
    cmake -B build \
      -DLLAMA_STATIC=ON -DBUILD_SHARED_LIBS=OFF \
      -DLLAMA_BUILD_TESTS=OFF -DLLAMA_BUILD_EXAMPLES=OFF -DLLAMA_BUILD_SERVER=OFF \
      -DGGML_NATIVE=OFF -DGGML_OPENMP=OFF \
      -DCMAKE_C_FLAGS="-mcpu=generic" -DCMAKE_CXX_FLAGS="-mcpu=generic" && \
    cmake --build build --config Release -j$(nproc)

# Combine static libs into single archive
RUN mkdir -p /out && \
    find build -name "*.a" -exec cp {} /out/ \; && \
    echo "Libraries found:" && ls -la /out/*.a && \
    echo "CREATE /out/libllama_combined.a" > /tmp/ar.mri && \
    for lib in /out/lib*.a; do echo "ADDLIB $lib" >> /tmp/ar.mri; done && \
    echo "SAVE" >> /tmp/ar.mri && \
    echo "END" >> /tmp/ar.mri && \
    cat /tmp/ar.mri && \
    ar -M < /tmp/ar.mri && \
    cp include/llama.h ggml/include/*.h /out/ && \
    echo "Combined library:" && ls -lh /out/libllama_combined.a

# =============================================================================
# Stage 3: Go build
# =============================================================================
FROM golang:1.23-bookworm AS builder
WORKDIR /build

RUN apt-get update && apt-get install -y --no-install-recommends build-essential && rm -rf /var/lib/apt/lists/*

# Copy llama artifacts
COPY --from=llama /out/libllama_combined.a /build/lib/llama/libllama_linux_arm64.a
COPY --from=llama /out/*.h /build/lib/llama/

# Go dependencies
COPY go.mod go.sum ./
RUN go mod download

# Source + UI
COPY . .
COPY --from=ui /ui/dist ./ui/dist

# Build
RUN CGO_ENABLED=1 go build -tags=localllm \
    -ldflags="-s -w -linkmode external -extldflags '-static' -X main.buildTime=$(date -u +%Y%m%d-%H%M%S)" \
    -o nornicdb ./cmd/nornicdb

# =============================================================================
# Stage 4: Runtime
# =============================================================================
FROM debian:bookworm-slim
WORKDIR /app

RUN apt-get update && apt-get install -y --no-install-recommends \
    ca-certificates tzdata wget && rm -rf /var/lib/apt/lists/* && \
    mkdir -p /data /app/models

COPY --from=builder /build/nornicdb /app/
COPY docker/entrypoint.sh /app/
RUN chmod +x /app/entrypoint.sh

# Model embedding: only copy when EMBED_MODEL=true (uses BuildKit mount to avoid layer bloat)
ARG EMBED_MODEL=false
RUN --mount=type=bind,source=models,target=/models,ro \
    if [ "$EMBED_MODEL" = "true" ]; then \
      if [ -f /models/bge-m3.gguf ]; then \
        cp /models/bge-m3.gguf /app/models/ && \
        echo "✓ Embedded bge-m3.gguf model ($(du -h /app/models/bge-m3.gguf | cut -f1))"; \
      else \
        echo "ERROR: EMBED_MODEL=true but models/bge-m3.gguf not found" && exit 1; \
      fi; \
    else \
      echo "→ BYOM mode (no embedded model)"; \
    fi

EXPOSE 7474 7687

HEALTHCHECK --interval=30s --timeout=10s --start-period=10s --retries=3 \
    CMD wget --spider -q http://localhost:7474/health || exit 1

ENV NORNICDB_DATA_DIR=/data \
    NORNICDB_HTTP_PORT=7474 \
    NORNICDB_BOLT_PORT=7687 \
    NORNICDB_EMBEDDING_PROVIDER=local \
    NORNICDB_EMBEDDING_MODEL=bge-m3 \
    NORNICDB_EMBEDDING_DIMENSIONS=1024 \
    NORNICDB_MODELS_DIR=/app/models \
    NORNICDB_EMBEDDING_GPU_LAYERS=0 \
    NORNICDB_NO_AUTH=true

ENTRYPOINT ["/app/entrypoint.sh"]
